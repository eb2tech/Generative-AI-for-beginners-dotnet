# Aplicaciones de IA para Visi√≥n y Audio

En esta lecci√≥n, aprende c√≥mo la IA de visi√≥n permite que tus aplicaciones generen e interpreten im√°genes. La IA de audio permite a tus aplicaciones generar audio e incluso transcribirlo en tiempo real.

---

## Visi√≥n

[![Explicaci√≥n de IA de visi√≥n](https://img.youtube.com/vi/QXbASt1KXuw/0.jpg)](https://youtu.be/QXbASt1KXuw?feature=shared)

_‚¨ÜÔ∏èHaz clic en la imagen para ver el video‚¨ÜÔ∏è_

Los enfoques de IA basados en visi√≥n se utilizan para generar e interpretar im√°genes. Esto puede ser √∫til para una amplia gama de aplicaciones, como reconocimiento de im√°genes, generaci√≥n de im√°genes y manipulaci√≥n de im√°genes. Los modelos actuales son multimodales, lo que significa que pueden aceptar una variedad de entradas, como texto, im√°genes y audio, y generar una variedad de salidas. En este caso, nos vamos a enfocar en el reconocimiento de im√°genes.

### Reconocimiento de im√°genes con MEAI

El reconocimiento de im√°genes va m√°s all√° de que el modelo de IA te diga qu√© cree que est√° presente en una imagen. Tambi√©n puedes hacer preguntas sobre la imagen, por ejemplo: _¬øCu√°ntas personas hay presentes y est√° lloviendo?_

Bien, vamos a poner a prueba el modelo y preguntarle cu√°ntos zapatos rojos hay en la primera foto y luego hacer que analice un recibo en alem√°n para saber cu√°nto debemos dejar de propina.

![Un collage que muestra ambas im√°genes que usar√° el ejemplo. La primera son varios corredores pero solo se ven sus piernas. La segunda es un recibo de restaurante en alem√°n](../../../translated_images/example-visual-image.e2fc4ffa5f01b3d65bb9bd5d23eebf97513bf486b761209b28fea06b63a11f6c.es.png)

> üßë‚Äçüíª**C√≥digo de ejemplo**: Puedes seguir [el c√≥digo de ejemplo aqu√≠](../../../03-CoreGenerativeAITechniques/src/Vision-01MEAI-GitHubModels).

1. Estamos utilizando MEAI y GitHub Models, as√≠ que instancia el `IChatClient` como lo hemos hecho antes. Tambi√©n comienza a crear un historial de conversaci√≥n.

    ```csharp
    IChatClient chatClient = new ChatCompletionsClient(
        endpoint: new Uri("https://models.github.ai/inference"),
        new AzureKeyCredential(githubToken)) // make sure to grab githubToken from the secrets or environment
    .AsChatClient("gpt-4o-mini");

    List<ChatMessage> messages = 
    [
        new ChatMessage(ChatRole.System, "You are a useful assistant that describes images using a direct style."),
        new ChatMessage(ChatRole.User, "How many red shoes are in the photo?") // we'll start with the running photo
    ];
    ```

1. La siguiente parte es cargar la imagen en un objeto `AIContent` y configurarlo como parte de nuestra conversaci√≥n, y luego enviarlo al modelo para que nos lo describa.

    ```csharp
    var imagePath = "FULL PATH TO THE IMAGE ON DISK";

    AIContent imageContent = new DataContent(File.ReadAllBytes(imagePath), "image/jpeg"); // the important part here is that we're loading it in bytes. The image could come from anywhere.

    var imageMessage = new ChatMessage(ChatRole.User, [imageContent]);

    messages.Add(imageMessage);

    var response = await chatClient.GetResponseAsync(messages);

    messages.Add(response.Message);

    Console.WriteLine(response.Message.Text);
    ```

1. Luego, para que el modelo trabaje en el recibo del restaurante -que est√° en alem√°n- y averig√ºe cu√°nto debemos dejar de propina:

    ```csharp
    // this will go after the previous code block
    messages.Add(new ChatMessage(ChatRole.User, "This is a receipt from a lunch. I had the sausage. How much of a tip should I leave?"));

    var receiptPath = "FULL PATH TO THE RECEIPT IMAGE ON DISK";

    AIContent receiptContent = new DataContent(File.ReadAllBytes(receiptPath), "image/jpeg");
    var receiptMessage = new ChatMessage(ChatRole.User, [receiptContent]);

    messages.Add(receiptMessage);

    response = await chatClient.GetResponseAsync(messages);
    messages.Add(response.Message);

    Console.WriteLine(response.Message.Text);
    ```

Aqu√≠ hay un punto que quiero destacar. Estamos conversando con un modelo de lenguaje, o m√°s apropiadamente, un modelo multimodal que puede manejar interacciones de texto, imagen (y audio). Y estamos llevando a cabo la conversaci√≥n con el modelo de forma normal. Claro, es un tipo diferente de objeto el que estamos enviando al modelo, `AIContent` instead of a `string`, but the workflow is the same.

> üôã **Need help?**: If you encounter any issues, [open an issue in the repository](https://github.com/microsoft/Generative-AI-for-beginners-dotnet/issues/new).

## Audio AI

[![Audio AI explainer video](https://img.youtube.com/vi/fuquPXRNqCo/0.jpg)](https://youtu.be/fuquPXRNqCo?feature=shared)

_‚¨ÜÔ∏èClick the image to watch the video‚¨ÜÔ∏è_

Real-time audio techniques allow your apps to generate audio and transcribe it in real-time. This can be useful for a wide range of applications, such as voice recognition, speech synthesis, and audio manipulation.

But we're going to have to transition away from MEAI and from the model we were using to Azure AI Speech Services.

To setup an Azure AI Speech Service model, [follow these directions](../02-SetupDevEnvironment/getting-started-azure-openai.md) but instead of choosing an OpenAI model, choose **Azure-AI-Speech**.

> **üóíÔ∏èNote:>** Audio is coming to MEAI, but as of this writing isn't available yet. When it is available we'll update this course.

### Implementing speech-to-text with Cognitive Services

You'll need the **Microsoft.CognitiveServices.Speech** NuGet package for this example.

> üßë‚Äçüíª**Sample code**: You can follow [along with sample code here](../../../03-CoreGenerativeAITechniques/src/Audio-01-SpeechMic).

1. The first thing we'll do (after grabbing the key and region of the model's deployment) is instantiate a `SpeechTranslationConfig`. Esto nos permitir√° dirigir al modelo para que tome audio hablado en ingl√©s y lo traduzca a texto escrito en espa√±ol.

    ```csharp
    var speechKey = "<FROM YOUR MODEL DEPLOYMENT>";
    var speechRegion = "<FROM YOUR MODEL DEPLOYMENT>";

    var speechTranslationConfig = SpeechTranslationConfig.FromSubscription(speechKey, speechRegion);
    speechTranslationConfig.SpeechRecognitionLanguage = "en-US";
    speechTranslationConfig.AddTargetLanguage("es-ES");
    ```

1. A continuaci√≥n, necesitamos obtener acceso al micr√≥fono y luego instanciar un objeto `TranslationRecognizer` que har√° la comunicaci√≥n con el modelo.

    ```csharp
    using var audioConfig = AudioConfig.FromDefaultMicrophoneInput();
    using var translationRecognizer = new TranslationRecognizer(speechTranslationConfig, audioConfig);
    ```

1. Finalmente, llamaremos al modelo y configuraremos una funci√≥n para manejar su respuesta.
   
    ```csharp
    var translationRecognitionResult = await translationRecognizer.RecognizeOnceAsync();
    OutputSpeechRecognitionResult(translationRecognitionResult);

    void OutputSpeechRecognitionResult(TranslationRecognitionResult translationRecognitionResult)
    {
        switch (translationRecognitionResult.Reason)
        {
            case ResultReason.TranslatedSpeech:
                Console.WriteLine($"RECOGNIZED: Text={translationRecognitionResult.Text}");
                foreach (var element in translationRecognitionResult.Translations)
                {
                    Console.WriteLine($"TRANSLATED into '{element.Key}': {element.Value}");
                }
                break;
            case ResultReason.NoMatch:
                // handle when speech could not be recognized
                break;
            case ResultReason.Canceled:
                // handle an error condition
                break;
        }
    }
    ```

Usar IA para procesar audio es un poco diferente de lo que hemos estado haciendo porque estamos utilizando los servicios de Azure AI Speech para hacerlo, pero los resultados de traducir audio hablado a texto son bastante potentes.

> üôã **¬øNecesitas ayuda?**: Si encuentras alg√∫n problema, [abre un issue en el repositorio](https://github.com/microsoft/Generative-AI-for-beginners-dotnet/issues/new).

Tenemos otro ejemplo que [demuestra c√≥mo realizar una conversaci√≥n de audio en tiempo real con Azure Open AI](../../../03-CoreGenerativeAITechniques/src/Audio-02-RealTimeAudio) - ¬°√©chale un vistazo!

## Recursos adicionales

- [Generar im√°genes con IA y .NET](https://learn.microsoft.com/dotnet/ai/quickstarts/quickstart-openai-generate-images?tabs=azd&pivots=openai)

## Lo que sigue

Has aprendido c√≥mo agregar capacidades de visi√≥n y audio a tus aplicaciones .NET. En la pr√≥xima lecci√≥n, descubre c√≥mo crear IA que tenga cierta capacidad de actuar de manera aut√≥noma.

üëâ [Consulta Agentes de IA](./04-agents.md).

**Descargo de responsabilidad**:  
Este documento ha sido traducido utilizando servicios de traducci√≥n autom√°tica basados en inteligencia artificial. Si bien nos esforzamos por garantizar la precisi√≥n, tenga en cuenta que las traducciones automatizadas pueden contener errores o imprecisiones. El documento original en su idioma nativo debe considerarse la fuente autorizada. Para informaci√≥n cr√≠tica, se recomienda una traducci√≥n profesional realizada por humanos. No nos hacemos responsables de malentendidos o interpretaciones err√≥neas que puedan surgir del uso de esta traducci√≥n.