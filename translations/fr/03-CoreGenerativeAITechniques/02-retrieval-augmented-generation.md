# G√©n√©ration Augment√©e par R√©cup√©ration (RAG)

Dans cette le√ßon, d√©couvrez comment utiliser la **G√©n√©ration Augment√©e par R√©cup√©ration (RAG)** dans vos applications d'IA. Cette technique permet d'enrichir la r√©ponse d'un mod√®le de langage en y int√©grant des informations r√©cup√©r√©es depuis une base de donn√©es - ou d'interagir directement avec vos donn√©es !

---

[![Vid√©o explicative sur RAG](https://img.youtube.com/vi/mY7O0OY2vho/0.jpg)](https://youtu.be/mY7O0OY2vho?feature=shared)

_‚¨ÜÔ∏èCliquez sur l'image pour regarder la vid√©o‚¨ÜÔ∏è_

La G√©n√©ration Augment√©e par R√©cup√©ration (RAG) est une technique utilis√©e pour enrichir la r√©ponse d'un mod√®le de langage avec des informations extraites d'une base de donn√©es.

L'architecture RAG repose sur deux phases principales : **R√©cup√©ration** et **G√©n√©ration**.

- **R√©cup√©ration** : Lorsqu'un utilisateur soumet une requ√™te, le syst√®me utilise un m√©canisme de r√©cup√©ration pour collecter des informations depuis une base de connaissances externe. Cette base de connaissances peut √™tre une base de donn√©es vectorielle, un document, ou autre.
- **G√©n√©ration** : Les informations r√©cup√©r√©es sont ensuite utilis√©es pour enrichir la requ√™te de l'utilisateur. Le mod√®le d'IA traite √† la fois les informations r√©cup√©r√©es et la requ√™te pour produire une r√©ponse enrichie.

## Avantages de RAG

- **Pr√©cision am√©lior√©e** : En enrichissant la requ√™te avec des informations pertinentes, le mod√®le peut g√©n√©rer des r√©ponses plus pr√©cises et r√©duire les hallucinations.
- **Informations √† jour** : Le mod√®le peut r√©cup√©rer les informations les plus r√©centes depuis la base de connaissances. Rappelons que les mod√®les de langage ont une date limite de connaissances, et enrichir la requ√™te avec des donn√©es r√©centes peut am√©liorer la r√©ponse.
- **Connaissances sp√©cifiques au domaine** : Le mod√®le peut int√©grer des informations tr√®s sp√©cifiques √† un domaine, ce qui le rend plus efficace dans des contextes sp√©cialis√©s.

## Les embeddings !

Nous avons attendu le plus longtemps possible avant d'introduire le concept des embeddings. Dans la phase de r√©cup√©ration de RAG, nous ne voulons pas transmettre l'int√©gralit√© de la base de donn√©es au mod√®le pour g√©n√©rer une r√©ponse. Nous souhaitons uniquement extraire les informations les plus pertinentes.

Il nous faut donc un moyen de comparer la requ√™te de l'utilisateur avec les donn√©es de la base de connaissances afin de r√©cup√©rer le strict minimum n√©cessaire pour enrichir la requ√™te.

C'est ici qu'interviennent les embeddings. Les embeddings permettent de repr√©senter des donn√©es dans un espace vectoriel. Cela nous permet de comparer math√©matiquement la similarit√© entre la requ√™te de l'utilisateur et les donn√©es de la base de connaissances, pour r√©cup√©rer les informations les plus pertinentes.

Vous avez peut-√™tre entendu parler des bases de donn√©es vectorielles. Ce sont des bases de donn√©es qui stockent des donn√©es dans un espace vectoriel, permettant une r√©cup√©ration tr√®s rapide bas√©e sur la similarit√©. Vous n'√™tes pas oblig√© d'utiliser une base de donn√©es vectorielle pour appliquer RAG, mais c'est un cas d'usage courant.

## Impl√©mentation de RAG

Nous utiliserons la biblioth√®que Microsoft.Extension.AI ainsi que [Microsoft.Extensions.VectorData](https://www.nuget.org/packages/Microsoft.Extensions.VectorData.Abstractions/) et [Microsoft.SemanticKernel.Connectors.InMemory](https://www.nuget.org/packages/Microsoft.SemanticKernel.Connectors.InMemory) pour impl√©menter RAG ci-dessous.

> üßë‚Äçüíª**Exemple de code :** Suivez l'exemple de code [ici](../../../03-CoreGenerativeAITechniques/src/RAGSimple-02MEAIVectorsMemory).
> 
> Vous pouvez √©galement voir comment impl√©menter une application RAG [en utilisant uniquement Semantic Kernel dans cet exemple de code source](../../../03-CoreGenerativeAITechniques/src/RAGSimple-01SK).

### Remplissage de la base de connaissances

1. Tout d'abord, nous avons besoin de donn√©es √† stocker. Nous allons utiliser une classe POCO qui repr√©sente des films.

    ```csharp
    public class Movie
    {
        [VectorStoreKey]
        public int Key { get; set; }

        [VectorStoreData]
        public string Title { get; set; }

        [VectorStoreData]
        public string Description { get; set; }

        [VectorStoreVector(384, DistanceFunction.CosineSimilarity)]
        public ReadOnlyMemory<float> Vector { get; set; }
    }
    ```

    En utilisant des attributs comme `[VectorStoreKey]` makes it easier for the vector store implementations to map POCO objects to their underlying data models.

2. Of course we're going to need that knowledge data populated. Create a list of `Movie` objects, and create an `InMemoryVectorStore`, nous aurons une collection de films.

    ```csharp
    var movieData = new List<Movie>
    {
        new Movie { Key = 1, Title = "The Matrix", Description = "A computer hacker learns from mysterious rebels about the true nature of his reality and his role in the war against its controllers." },
        new Movie { Key = 2, Title = "Inception", Description = "A thief who steals corporate secrets through the use of dream-sharing technology is given the inverse task of planting an idea into the mind of a C.E.O." },
        new Movie { Key = 3, Title = "Interstellar", Description = "A team of explorers travel through a wormhole in space in an attempt to ensure humanity's survival." }
    };

    var vectorStore = new InMemoryVectorStore();
    var movies = vectorStore.GetCollection<int, Movie>("movies");
    await movies.CreateCollectionIfNotExistsAsync();

    ```

3. Ensuite, nous devons convertir notre base de connaissances (l'objet `movieData`) en embeddings, puis les stocker dans une base vectorielle en m√©moire. Pour cr√©er ces embeddings, nous utiliserons un mod√®le diff√©rent - un mod√®le d'embeddings au lieu d'un mod√®le de langage.

    ```csharp
    var endpoint = new Uri("https://models.github.ai/inference");
    var modelId = "text-embedding-3-small";
    var credential = new AzureKeyCredential(githubToken); // githubToken is retrieved from the environment variables

    IEmbeddingGenerator<string, Embedding<float>> generator =
            new EmbeddingsClient(endpoint, credential)
        .AsEmbeddingGenerator(modelId);

    foreach (var movie in movieData)
    {
        // generate the embedding vector for the movie description
        movie.Vector = await generator.GenerateEmbeddingVectorAsync(movie.Description);
        
        // add the overall movie to the in-memory vector store's movie collection
        await movies.UpsertAsync(movie);
    }
    ```

    Notre objet g√©n√©rateur est de type `IEmbeddingGenerator<string, Embedding<float>>` type. This means it is expecting inputs of `string` and outputs of `Embedding<float>`. Nous utilisons √† nouveau les mod√®les GitHub, ce qui n√©cessite le package **Microsoft.Extensions.AI.AzureAIInference**. Cependant, vous pourriez tout aussi bien utiliser **Ollama** ou **Azure OpenAI**.

> üóíÔ∏è**Remarque :** En g√©n√©ral, vous ne cr√©erez les embeddings pour votre base de connaissances qu'une seule fois avant de les stocker. Cela ne sera pas fait √† chaque fois que vous ex√©cutez l'application. Cependant, comme nous utilisons une base en m√©moire, il est n√©cessaire de recr√©er les embeddings √† chaque red√©marrage de l'application.

### R√©cup√©ration des connaissances

1. Passons maintenant √† la phase de r√©cup√©ration. Nous devons interroger la base vectorielle pour trouver les informations les plus pertinentes en fonction de la requ√™te de l'utilisateur. Pour cela, il faut transformer la requ√™te de l'utilisateur en un vecteur d'embedding.

    ```csharp
    // generate the embedding vector for the user's prompt
    var query = "I want to see family friendly movie";
    var queryEmbedding = await generator.GenerateEmbeddingVectorAsync(query);

    var searchOptions = new VectorSearchOptions
    {
        Top = 1,
        VectorPropertyName = "Vector"
    };

    // search the knowledge store based on the user's prompt
    var searchResults = await movies.VectorizedSearchAsync(queryEmbedding, searchOptions);

    // let's see the results just so we know what they look like
    await foreach (var result in searchResults.Results)
    {
        Console.WriteLine($"Title: {result.Record.Title}");
        Console.WriteLine($"Description: {result.Record.Description}");
        Console.WriteLine($"Score: {result.Score}");
        Console.WriteLine();
    }
    ```

### G√©n√©ration de la r√©ponse

Nous arrivons maintenant √† la phase de g√©n√©ration de RAG. Ici, nous fournissons au mod√®le de langage le contexte suppl√©mentaire trouv√© lors de la phase de r√©cup√©ration, afin qu'il puisse formuler une r√©ponse plus pertinente. Cela ressemblera beaucoup aux compl√©tions de chat que nous avons vues pr√©c√©demment - sauf que cette fois, nous fournissons au mod√®le √† la fois la requ√™te de l'utilisateur et les informations r√©cup√©r√©es.

Rappelez-vous, lorsque nous avons utilis√© des objets `ChatMessage` pour interagir avec le mod√®le, ceux-ci avaient des r√¥les comme **System**, **User**, et **Assistant**. La plupart du temps, nous d√©finirons probablement les r√©sultats de recherche comme un message **User**.

Ainsi, nous pourrions faire quelque chose comme ce qui suit en parcourant les r√©sultats de la recherche vectorielle¬†:

```csharp

// assuming chatClient is instatiated as before to a language model
// assuming the vector search is done as above
// assuming List<ChatMessage> conversation object is already instantiated and has a system prompt

conversation.Add(new ChatMessage(ChatRole.User, query)); // this is the user prompt

// ... do the vector search

// add the search results to the conversation
await foreach (var result in searchResults.Results)
{
    conversation.Add(new ChatMessage(ChatRole.User, $"This movie is playing nearby: {result.Record.Title} and it's about {result.Record.Description}"));
}

// send the conversation to the model
var response = await chatClient.GetResponseAsync(conversation);

// add the assistant message to the conversation
conversation.Add(new ChatMessage(ChatRole.Assistant, response.Message));

//display the conversation
Console.WriteLine($"Bot:> {response.Message.Text});
```

> üôã **Besoin d'aide ?** : Si vous rencontrez des probl√®mes, [ouvrez un ticket dans le d√©p√¥t](https://github.com/microsoft/Generative-AI-for-beginners-dotnet/issues/new).

## Ressources suppl√©mentaires

- [GenAI pour les d√©butants : RAG et bases de donn√©es vectorielles](https://github.com/microsoft/generative-ai-for-beginners/blob/main/15-rag-and-vector-databases/README.md)
- [Cr√©er une application de recherche IA vectorielle avec .NET](https://learn.microsoft.com/dotnet/ai/quickstarts/quickstart-ai-chat-with-data?tabs=azd&pivots=openai)

## Prochaine √©tape

Maintenant que vous avez vu comment impl√©menter RAG, vous comprenez √† quel point cet outil peut √™tre puissant dans vos applications d'IA. Il peut fournir des r√©ponses plus pr√©cises, des informations actualis√©es, et des connaissances sp√©cifiques √† un domaine √† vos utilisateurs.

üëâ [Prochaine √©tape : apprenez √† ajouter la vision et l'audio √† vos applications d'IA](03-vision-audio.md).

**Avertissement** :  
Ce document a √©t√© traduit √† l'aide de services de traduction automatique bas√©s sur l'IA. Bien que nous nous efforcions d'assurer l'exactitude, veuillez noter que les traductions automatis√©es peuvent contenir des erreurs ou des inexactitudes. Le document original dans sa langue d'origine doit √™tre consid√©r√© comme la source faisant autorit√©. Pour des informations critiques, il est recommand√© de faire appel √† une traduction humaine professionnelle. Nous d√©clinons toute responsabilit√© en cas de malentendus ou de mauvaises interpr√©tations r√©sultant de l'utilisation de cette traduction.